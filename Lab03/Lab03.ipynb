{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "CtnHxc20lVGg"
   },
   "source": [
    "# Lab03: Tiền xử lý và mô hình hóa dữ liệu\n",
    "\n",
    "\n",
    "Họ tên: ...\n",
    "\n",
    "MSSV: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "LUs_Y7MUlVGk"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMWLHZ-_lVGl"
   },
   "source": [
    "## Cách làm bài và nộp bài (bạn cần đọc kỹ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2nqQsadlVGm"
   },
   "source": [
    "&#9889; Bạn lưu ý là mình sẽ dùng chương trình hỗ trợ chấm bài nên bạn cần phải tuân thủ chính xác qui định mà mình đặt ra, nếu không rõ thì hỏi, chứ không nên tự tiện làm theo ý của cá nhân.\n",
    "\n",
    "**Cách làm bài**\n",
    "\n",
    "Bạn sẽ làm trực tiếp trên file notebook này. Đầu tiên, bạn điền họ tên và MSSV vào phần đầu file ở bên trên. Trong file, bạn làm bài ở những chỗ có ghi là:\n",
    "```python\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "```\n",
    "hoặc đối với những phần code không bắt buộc thì là:\n",
    "```python\n",
    "# YOUR CODE HERE (OPTION)\n",
    "```\n",
    "hoặc đối với markdown cell thì là:\n",
    "```markdown\n",
    "YOUR ANSWER HERE\n",
    "```\n",
    "Tất nhiên, khi làm thì bạn xóa dòng `raise NotImplementedError()` đi.\n",
    "Đối những phần yêu cầu code thì thường ở ngay phía dưới sẽ có một (hoặc một số) cell chứa các bộ test để giúp bạn biết đã code đúng hay chưa; nếu chạy cell này không có lỗi gì thì có nghĩa là qua được các bộ test. Trong một số trường hợp, các bộ test có thể sẽ không đầy đủ; nghĩa là, nếu không qua được test thì là code sai, nhưng nếu qua được test thì chưa chắc đã đúng.\n",
    "\n",
    "Trong khi làm bài, bạn có thể cho in ra màn hình, tạo thêm các cell để test. Nhưng khi nộp bài thì bạn xóa các cell mà bạn tự tạo, xóa hoặc comment các câu lệnh in ra màn hình. Bạn lưu ý <font color=red>không được tự tiện xóa các cell hay sửa code của Thầy</font> (trừ những chỗ được phép sửa như đã nói ở trên).\n",
    "\n",
    "Trong khi làm bài, thường xuyên `Ctrl + S` để lưu lại bài làm của bạn, tránh mất mát thông tin.\n",
    "\n",
    "\n",
    "*Nên nhớ mục tiêu chính ở đây là <font color=green>học, học một cách chân thật</font>. Bạn có thể thảo luận ý tưởng với bạn khác cũng như tham khảo các nguồn trên mạng, nhưng sau cùng <font color=green>code và bài làm phải là của bạn, dựa trên sự hiểu thật sự của bạn</font>. Khi tham khảo các nguồn trên mạng thì bạn cần ghi rõ nguồn trong bài làm. Bạn không được tham khảo bài làm của các bạn năm trước (vì nếu làm vậy thì bao giờ bạn mới có thể tự mình suy nghĩ để giải quyết vấn đề); sau khi kết thúc môn học, bạn cũng không được đưa bài làm cho các bạn khóa sau hoặc public bài làm trên Github (vì nếu làm vậy thì sẽ ảnh hưởng tới việc học của các bạn khóa sau). Nếu bạn có thể làm theo những gì mình nói thì điểm của bạn có thể sẽ không cao nhưng bạn sẽ có được những bước tiến thật sự. <font color=red>Trong trường hợp bạn vi phạm những điều mình nói ở trên thì sẽ bị 0 điểm cho toàn bộ môn học.</font>*\n",
    "\n",
    "**Cách nộp bài**\n",
    "\n",
    "Khi chấm bài, đầu tiên mình sẽ chọn `Kernel` - `Restart & Run All`, để restart và chạy tất cả các cell trong notebook của bạn; do đó, trước khi nộp bài, bạn nên chạy thử `Kernel` - `Restart & Run All` để đảm bảo mọi chuyện diễn ra đúng như mong đợi.\n",
    "\n",
    "Sau đó, bạn tạo thư mục nộp bài theo cấu trúc sau:\n",
    "- Thư mục `MSSV` (vd, nếu bạn có MSSV là 1234567 thì bạn đặt tên thư mục là `1234567`)\n",
    "    - File `Lab03.ipynb` (không cần nộp các file khác)\n",
    "\n",
    "Cuối cùng, bạn nén thư mục `MSSV` này lại và nộp ở link trên moodle. Đuôi của file nén phải là .zip (chứ không được .rar hay gì khác).\n",
    "\n",
    "<font color=red>Bạn lưu ý tuân thủ chính xác qui định nộp bài ở trên.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "vIU2_LomlVGo"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTy3m42ZlVGo"
   },
   "source": [
    "## Môi trường code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlr2NIyglVGp"
   },
   "source": [
    "Ta thống nhất trong môn này: dùng phiên bản các package như trong file \"min_ds-env.yml\". Cách tạo/cập-nhật môi trường code từ file \"min_ds-env.yml\" đã được nói ở file \"02_BeforeClass-Notebook_Python.pdf\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-djgfWxulVGq"
   },
   "source": [
    "Check môi trường code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZC2XmNdKlVGr",
    "outputId": "8d26ad08-469e-4916-ae01-ca0bf7f6f1ca"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable, sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dTHKb32lVGt"
   },
   "source": [
    "Nếu không có vấn đề gì thì file chạy python sẽ là file của môi trường code \"min_ds-env\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "1V_NYjMxlVGt"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "ovxfxtNMlVGu"
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "id": "zADGZAPMlVGu"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # seaborn là thư viện được xây trên matplotlib, \n",
    "                      # giúp việc visualization đỡ khổ hơn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram') # Để trực quan hóa pipeline\n",
    "\n",
    "# You can also import other things ...\n",
    "# YOUR CODE HERE (OPTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "Z0JL7XEFlVGv"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "bzcfEvRClVGv"
   },
   "source": [
    "## Thu thập dữ liệu\n",
    "\n",
    "Bộ dữ liệu được sử dụng trong bài tập là bộ dữ liệu đã được thu thập sẵn cho việc dự đoán bệnh tim ([Tham khảo](https://archive.ics.uci.edu/ml/datasets/heart+disease)); Ở đây mình đã thay đổi một số thứ để phù hợp với mục tiêu của bài lab\n",
    "\n",
    "\n",
    "Các file dữ liệu bao gồm: \n",
    "- File \"lab03_train.csv\": tập dữ liệu train\n",
    "- File \"lab03_test.csv\": tập dữ liệu test\n",
    "- File \"description.txt\": mô tả ý nghĩa của các cột"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "cDE_MU8VlVGv"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "qUIzd1oFlVGw"
   },
   "source": [
    "## Khám phá dữ liệu (đủ để có thể xác định câu hỏi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "sFmVedwNlVGw",
    "outputId": "aeb7c0d4-6a89-41b2-af5c-a5c7336f0a6c"
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('lab03_train.csv') # Cho cột index là cột PassengerId\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKu3RUoRaSS7",
    "outputId": "29a78c5c-6aec-45d4-cc4b-195d246d8915"
   },
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OAxtr7XlVGw"
   },
   "source": [
    "### Dữ liệu có bao nhiêu dòng và bao nhiêu cột?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zlZ1c7EflVGx",
    "outputId": "469194cd-ebcc-433b-e840-02940b6dda68"
   },
   "outputs": [],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4Um_o5blVGx"
   },
   "source": [
    "### Mỗi dòng có ý nghĩa gì? Có vấn đề các dòng có ý nghĩa khác nhau không?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ql5VsnYVlVGx"
   },
   "source": [
    "Quan sát sơ bộ dữ liệu ta thấy mỗi dòng chứa thông tin của một bệnh nhân, và có vẻ không có vấn đề các dòng có ý nghĩa khác nhau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ih5D0w0WlVGy"
   },
   "source": [
    "### Dữ liệu có các dòng bị lặp không?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8gMMMlmlVGy",
    "outputId": "179f55c1-d3b9-4a91-fa2f-43080fd2b760"
   },
   "outputs": [],
   "source": [
    "# Số dòng bị lặp\n",
    "data_df.index.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLl5KluIlVGy"
   },
   "source": [
    "### Mỗi cột có ý nghĩa gì?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KW2RYNgwlVGy"
   },
   "source": [
    "Xem file \"description.txt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "scpKAvIRlVGz",
    "outputId": "2f15aff4-8041-44c3-81d2-528e2e0e3473"
   },
   "outputs": [],
   "source": [
    "with open('description.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7gIF118lVGz"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rOAPNhBlVG0"
   },
   "source": [
    "Khám phá dữ liệu đến đây là đã đủ để có thể đưa ra câu hỏi cần trả lời. Sau khi đưa ra câu hỏi cần trả lời thì ta sẽ tiến hành ngay bước tiền xử lý là tách ra tập validation và tập test. Sau đó, ta có thể tiếp tục khám phá trên *tập train* (tập mà đã tách ra tập validation và tập test) để hiểu hơn về dữ liệu.\n",
    "\n",
    "Sở dĩ ta cần *tách sớm tập validation và tập test* vì 2 tập này (đặc biệt là tập test) cần phải được giữ bí mật để kết quả đánh giá được khách quan. Nếu ta khám phá dữ liệu nhiều quá, hiểu dữ liệu nhiều quá rồi mới tách các tập thì kết quả trên tập validation và tập test có thể sẽ không được khách quan vì ta có thể dùng các hiểu biết khi khám phá dữ liệu (có tập validation và tập test trong đó) để đưa ra các lựa chọn khi tiền xử lý và mô hình hóa dữ liệu (ở đây, mình muốn nói đến các hiểu biết mà chỉ đúng với tập dữ liệu cụ thể này chứ không thật sự là đúng)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LujfMGvIlVG0"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jx3A7ZIglVG0"
   },
   "source": [
    "## Đưa ra câu hỏi cần trả lời"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUhBEvzulVG0"
   },
   "source": [
    "Quan trọng nhất ở bước này là ta phải xác định đâu là ouput và input. Về các cột input, nếu được thì ta cố gắng xác định những cột nào sẽ không dùng đến dựa vào ý nghĩa của các cột và sẽ bỏ luôn các cột này để đơn giản hóa cho các bước lúc sau (nhất là trong trường hợp dữ liệu có nhiều cột); với những cột mà không chắc chắn là nên bỏ hay nên giữ thì tạm cứ để đó, và ta sẽ làm ở bước tiền xử lý lúc sau.\n",
    "\n",
    "Việc tìm ra câu trả lời này cho câu hỏi này thật ra không có nhiều ý nghĩa trong thực tế; mục đích chính của bài tập này và của bài tập này là để tập luyện tiền xử lý + mô hình hóa dữ liệu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "WlhcRL0YlVG1"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "dxHaKceolVG1"
   },
   "source": [
    "## Khám phá dữ liệu (để biết cách tách các tập)\n",
    "Để biết cách tách các tập thì ta cần khám phá thêm cột output một ít:\n",
    "- Cột này hiện có kiểu dữ liệu là gì? Trong bài toán hồi qui thì cột output bắt buộc phải có dạng số; nếu hiện chưa có dạng số (ví dụ, số nhưng được lưu dưới dạng chuỗi) thì ta cần chuyển sang dạng số rồi mới tách các tập.\n",
    "- Cột này có giá trị thiếu không? Nếu có giá trị thiếu thì ta sẽ bỏ các dòng mà output có giá trị thiếu rồi mới tách các tập (loại học mà học từ dữ liệu trong đó output có giá trị thiếu được gọi là bán giám sát (semi-supervised); trong phạm vi môn học, ta không đụng tới kỹ thuật này).\n",
    "- Nếu cột này có dạng categorical (phân lớp) thì tỉ lệ các lớp như thế nào? Nếu tỉ lệ các lớp bị chênh lệch nhau quá nhiều thì có thể ta sẽ cần quay lại bước thu thập dữ liệu và thu thập thêm để cho tỉ lệ các lớp không bị chênh lệnh quá nhiều (hoặc khi đánh giá ta cần có một độ đo phù hợp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2ksfSf-lVG1",
    "outputId": "e0d35b1a-32af-4a71-991f-04ade7b4c250"
   },
   "outputs": [],
   "source": [
    "# Cột output hiện có kiểu dữ liệu gì?\n",
    "data_df['target'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BcQnoMbxlVG1",
    "outputId": "ee975ddf-b2c0-4b39-875c-d169a8d71192"
   },
   "outputs": [],
   "source": [
    "# Cột output có bao nhiêu giá trị thiếu?\n",
    "data_df['target'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "i758Nmi0lVG2",
    "outputId": "33a97560-dd09-4bd4-9f03-d3f025c7aa48"
   },
   "outputs": [],
   "source": [
    "# Tỉ lệ các lớp trong cột output?\n",
    "data_df.target.value_counts(normalize=True).plot(kind=\"bar\", color=[\"red\", \"blue\"])\n",
    "data_df['target'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Us43QXkvlVG2"
   },
   "source": [
    "OK, như vậy là không có vấn đề gì cả. Tỉ lệ giữa các lớp cũng khá cân bằng, vậy thì ta sẽ có thể áp dụng các kỹ thuật thông thường để giải quyết bài toán này"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NgcvfyEPlVG2"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQXS782plVG3",
    "tags": []
   },
   "source": [
    "## Tiền xử lý (tách các tập)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOFzqJU_lVG3"
   },
   "source": [
    "Bây giờ ta sẽ thực hiện bước tiền xử lý là tách tập validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "id": "GOxpBQ2hlVG3"
   },
   "outputs": [],
   "source": [
    "# Tách X và y\n",
    "y_sr = data_df[\"target\"] # sr là viết tắt của series\n",
    "X_df = data_df.drop(\"target\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "id": "tBKNBvtPlVG3"
   },
   "outputs": [],
   "source": [
    "# Tách tập huấn luyện và tập validation theo tỉ lệ 80%:20%\n",
    "train_X_df, val_X_df, train_y_sr, val_y_sr = \\\n",
    "                              train_test_split(X_df, y_sr, \n",
    "                                               test_size=0.2, \n",
    "                                               stratify=y_sr, \n",
    "                                               random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rxUbZC8IlVG3",
    "outputId": "1a713527-f08c-475d-d0df-48cd8cde94d3"
   },
   "outputs": [],
   "source": [
    "train_X_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y6QO5DEwlVG4",
    "outputId": "971dfdc1-a2ff-471b-8938-9195baa65fff"
   },
   "outputs": [],
   "source": [
    "train_y_sr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tMzu6_kIlVG4",
    "outputId": "ee2cba7c-081b-4ff1-f65f-51e76d76fcf7"
   },
   "outputs": [],
   "source": [
    "val_X_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "as6Tz8telVG4",
    "outputId": "32486dfa-2f8d-46a5-cfb0-e92a80fb12ac"
   },
   "outputs": [],
   "source": [
    "val_y_sr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEJirtzJlVG4",
    "outputId": "42a59476-02d3-4b29-f3d3-8aae78dd009e"
   },
   "outputs": [],
   "source": [
    "train_X_df.head().index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "nxnp-5gilVG4"
   },
   "source": [
    "&#9889; Mình đã cố định `random_state` trong `train_test_split` để đảm bảo kết quả của mình ra giống với của bạn. Tuy nhiên, mình không biết là với các hệ điều hành khác nhau thì điều này có được đảm bảo không. Kết quả của câu lệnh `train_X_df.head().index` của mình ra 5 giá trị là: 214, 160, 23, 57, 206. Nếu của bạn ra khác thì bạn báo lại cho mình trên moodle (hoặc zalo), vì nếu ra khác thì các kết quả lúc sau của bạn cũng sẽ khác với của mình. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "b9EXZJOalVG5"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "83Q7v7BYlVG5"
   },
   "source": [
    "## Khám phá dữ liệu trên tập train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEM0lFBHlVG5"
   },
   "source": [
    "Sau khi đã tách ra các tập thì ta có thể thoải mái khám phá trên tập huấn luyện mà không lo sẽ làm kết quả trên tập validation và tập test bị mất đi sự khách quan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LY1HXxl3lVG5"
   },
   "source": [
    "### Mỗi cột input hiện đang có kiểu dữ liệu gì? Có cột nào có kiểu dữ liệu chưa phù hợp để có thể xử lý tiếp không?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGmgPdoulVG5",
    "outputId": "39de2123-2622-449e-9882-c71b594c803d"
   },
   "outputs": [],
   "source": [
    "train_X_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kp_SG9hwlVG6"
   },
   "source": [
    "Có vẻ các cột đều có kiểu dữ liệu phù hợp. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtmDTZWUlVG6"
   },
   "source": [
    "### Với mỗi cột input có kiểu dữ liệu dạng số, các giá trị được phân bố như thế nào?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04n9XUeIlVG6",
    "outputId": "c72bd509-47fa-4c51-e7fe-634174a99eb5"
   },
   "outputs": [],
   "source": [
    "train_X_df.dtypes[train_X_df.dtypes != object]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "UBpuFrXrcoVE",
    "outputId": "75d5a513-2840-4f6a-a6da-182c635879e1"
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.float\", \"{:.2f}\".format)\n",
    "train_X_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "L12O7thLlVG8"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbGOiPEglVG8"
   },
   "source": [
    "## Tiền xử lý (tập huấn luyện) (3.5đ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "3EvZW1chlVG8"
   },
   "source": [
    "Đầu tiên, ta sẽ thêm và bỏ một số cột như sau: \n",
    "- Với cột `cp`, ta sẽ tiến hành rút trích ra cột `cp_reduced` tương ứng. Khi khám phá, bạn sẽ thấy `cp` có khá nhiều giá trị khác nhau trong tập train (bạn xem thử thì sẽ thấy có 10 giá trị, trong tập test có thể nhiều hơn), trong đó có các giá trị chỉ xuất hiện một hoặc với số lần rất ít; nếu ta để nguyên thì khi chuyển sang dạng số bằng phương pháp one-hot sẽ có nhiều cột &#8594; dễ bị overfit. Ta sẽ xử lý vấn đề này như sau: chỉ lấy `num_top_cp_values` (ví dụ, 4) giá trị xuất hiện nhiều nhất, các giá trị còn lại sẽ được thay thế bằng giá trị `-1` (Khi mô hình hóa, ta sẽ mã hóa cột này dưới dạng one-hot nên chọn giá trị nào không nằm trong `top_cp_values` để thay thế cũng được, nhưng mình sẽ thống nhất chọn giá trị `-1`). Lúc sau, ta sẽ thí nghiệm để chọn ra giá trị `num_top_cp_values` phù hợp. Sau khi xử lý cột `cp_reduced` như vừa nói, ta thêm cột này vào dataframe và bỏ cột `cp` đi.\n",
    "- Bỏ cột `thalach` vì cột này có quá nhiều giá thiếu.\n",
    "\n",
    "\n",
    "Class `ColAdderDropper` ở dưới đây sẽ thực hiện các bước ở trên. Vì trong các bước ở trên, có bước ta cần tính toán các giá trị từ tập huấn luyện (`num_top_titles` giá trị của cột \"Title\" mà xuất hiện nhiều nhất) và dùng các giá trị này để \"transform\" tập dữ liệu (có thể là tập huấn luyện, có thể là tập validation hoặc tập kiểm tra) nên ta phải tự định nghĩa một class theo dạng \"transformer\" của Sklearn (để lúc sau có thể dùng pipeline của Sklearn) và trong đó ta phải tự định nghĩa phương thức `fit` và `transform` (còn nếu chỉ cần \"transform\" tập dữ liệu mà không cần tính toán giá trị gì từ tập huấn luyện thì dùng `FunctionTransformer` như trong file \"08-Demo.ipynb\" sẽ tiện lợi hơn). Bạn lưu ý: phương thức `fit` chỉ được dùng trên tập huấn luyện, còn phương thức `transform` (sau khi đã `fit`) có thể được dùng cho bất kỳ tập nào.\n",
    "\n",
    "Ở dưới, mình đã cài đặt sẵn phương thức `fit`; sau khi `fit`, các giá trị của cột `cp` cùng với số lần xuất hiện sẽ được lưu vào thuộc tính `self.cp_counts_` (khi \"transform\" thì không cần dùng đến thông tin này, nhưng có thể bạn sẽ muốn xem thông tin này), và `num_top_cp_values` giá trị xuất hiện nhiều nhất sẽ được lưu vào `self.top_cp_values_` (`num_top_cp_values` là siêu tham số mà phải chỉ định khi tạo ra một đối tượng thuộc class này). Nhiệm vụ của bạn là cài đặt phương thức `transform` (trong đó, sẽ cần dùng đến `self.top_cp_values_`); bạn lưu ý không làm thay đổi dữ liệu ở `X_df` truyền vào.\n",
    "\n",
    "Ngoài ra, như bạn có thể thấy ở bên dưới, class `ColAdderDropper` được kế thừa từ 2 class của Sklearn là `BaseEstimator` và `TransformerMixin`. Việc kế thừa này giúp class của ta tự động có các phương thức như `set_params`, `get_params`, `fit_transform` (nếu không thì ta sẽ phải tự định nghĩa các phương thức này). Nếu muốn tìm hiểu thêm về cách viết class theo dạng của Sklearn, bạn có thể đọc [ở đây](https://scikit-learn.org/stable/developers/develop.html?highlight=baseestimator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "id": "v5VbKC_ilVG8",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bbd42fec4a1b01ae8a8a58dc28e06d2",
     "grade": false,
     "grade_id": "cell-c2cb62acb65582f6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class ColAdderDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_top_cp_values=3):\n",
    "        self.num_top_cp_values = num_top_cp_values\n",
    "        \n",
    "    def fit(self, X_df, y=None):\n",
    "        self.cp_counts_ = X_df['cp'].value_counts()\n",
    "        cps = list(self.cp_counts_.index)\n",
    "        self.top_cp_values_ = cps[:max(1, min(self.num_top_cp_values, len(cps)))]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X_df, y=None):\n",
    "        \n",
    "        out_df = X_df.copy()\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        out_df = out_df.sort_index(axis=1)\n",
    "        return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CYn5spSlVG9",
    "outputId": "5557eda9-c09e-4fe4-e236-3925d500e644"
   },
   "outputs": [],
   "source": [
    "# TEST FIT METHOD\n",
    "col_adderdropper = ColAdderDropper(num_top_cp_values=3)\n",
    "col_adderdropper.fit(data_df)\n",
    "print(col_adderdropper.cp_counts_)\n",
    "print()\n",
    "print(col_adderdropper.top_cp_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "deletable": false,
    "editable": false,
    "id": "ujHTyrGJlVG9",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "258f156033739a9ad92fb68786c9f38b",
     "grade": true,
     "grade_id": "cell-7a54f3df0d0a2556",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "83e513c8-db6d-4a49-d251-bc2ebde967d6"
   },
   "outputs": [],
   "source": [
    "# TEST TRANSFORM METHOD\n",
    "fewer_cols_train_X_df = col_adderdropper.transform(train_X_df)\n",
    "assert set(fewer_cols_train_X_df.columns) == \\\n",
    "                                {'age', 'ca', 'chol', 'cp_reduced', 'exang', 'fbs', 'oldpeak', 'restecg', 'sex', 'slope', 'thal', 'trestbps'}\n",
    "                                \n",
    "assert np.all(fewer_cols_train_X_df['cp_reduced'].value_counts() == \\\n",
    "              pd.Series([94, 55, 29, 15], \n",
    "                        [0, 2, 1, -1]))\n",
    "fewer_cols_train_X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "k0Y6VOjvlVG-"
   },
   "source": [
    "Đến đây, các bạn sẽ phải rút ra danh sách các cột dạng số (numerical) và các cột không phải dạng số (categorical). Các bước tiền xử lý tiếp theo như sau:\n",
    "- Với các cột dạng số, ta sẽ điền giá trị thiếu bằng giá trị mean của cột <font color=gray>(gợi ý: dùng `SimpleImputer` trong Sklearn)</font>. Với *tất cả* các cột dạng số trong tập huấn luyện, ta đều cần tính mean, vì ta không biết được cột nào sẽ bị thiếu giá trị khi dự đoán với các véc-tơ input mới. \n",
    "- Với các cột không phải dạng số và không có thứ tự:\n",
    "    - Ta sẽ điền giá trị thiếu bằng giá trị mode (giá trị xuất hiện nhiều nhất) của cột <font color=gray>(gợi ý: dùng `SimpleImputer` trong Sklearn)</font>. Với *tất cả* các cột không có dạng số và không có thứ tự, ta đều cần tính mode, vì ta không biết được cột nào sẽ bị thiếu giá trị khi dự đoán với các véc-tơ input mới.\n",
    "    - Sau đó, ta sẽ chuyển sang dạng số bằng phương pháp mã hóa one-hot <font color=gray>(gợi ý: dùng `OneHotEncoder` trong Sklearn, để ý tham số `handle_unknown` vì khi dự đoán với các véc-tơ input mới ...)</font>.\n",
    "\n",
    "- Cuối cùng, khi tất cả các cột đã được điền giá trị thiếu và đã có dạng số, ta sẽ tiến hành chuẩn hóa khoảng giá trị bằng cách trừ đi mean và chia cho std của cột để giúp cho các thuật toán tối ưu Gradient Descent, LBFGS, ... hội tụ nhanh hơn <font color=gray>(gợi ý: dùng `StandardScaler` trong Sklearn)</font>.\n",
    "\n",
    "Nhiệm vụ của bạn là tạo ra một pipeline, đặt tên là `preprocess_pipeline`, bao gồm: bước thêm cột `Title` và bỏ các cột (đã cài ở class `ColAdderDropper`, bạn để `num_top_cp_values=3`), và tất cả các bước ở đây (bạn lưu ý làm đúng theo thứ tự của các bước và các cột mà mình đã mô tả). Sau khi tạo ra được pipeline này rồi, bạn sẽ gọi phương thức `fit_transform` với đầu vào là `train_X_df` để tính các giá trị từ tập huấn luyện (ví dụ, `top_cp_values_` ở bước thêm và xóa cột, mean và mode ở bước xử lý giá trị thiếu, mean và std ở bước chuẩn hóa) và đồng thời tiền xử lý `train_X_df`; kết quả trả về sẽ là `train_X_df` sau khi đã tiền xử lý, là một mảng Numpy, bạn đặt tên là `preprocessed_train_X`. <font color=gray>(Gợi ý: bạn đọc cách sử dụng pipeline ở [document](https://scikit-learn.org/stable/modules/compose.html#transforming-target-in-regression), có thể bỏ qua mục 6.1.2; bạn sẽ cần dùng `Pipeline`/`make_pipeline` và `ColumnTransformer`/`make_column_transformer`.)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "As9Dp0wZlVG-",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7a1d4ae5e4fa50b60b4998de6be96a1",
     "grade": false,
     "grade_id": "cell-ae75d7dfa7256c7f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "3d19caf1-2bf5-41cf-a65f-acdb16077dbd"
   },
   "outputs": [],
   "source": [
    "# Các bạn tự xác định xem cột nào là numerical hoặc categorical \n",
    "# (Gợi ý: xem xét các cột có số lượng giá trị khác nhau <15 )\n",
    "# YOUR CODE HERE\n",
    "categorical_cols = []\n",
    "numerics_cols = []\n",
    "\n",
    "\n",
    "#preprocess_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "deletable": false,
    "editable": false,
    "id": "sJKDf9IqlVG_",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34cd22a6a9f34822f20f8d3c89115986",
     "grade": true,
     "grade_id": "cell-1cf65ae2cdb14c0c",
     "locked": true,
     "points": 2.5,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "ed876cd7-3e8a-43ab-abc2-72d65f529327"
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert preprocessed_train_X.shape == (193, 29)\n",
    "row0 = [1.026, 1.924, -0.953, 0.495, 0.832, -0.503, -0.386, -0.269, -0.102, -0.29, -0.974, -0.421, 1.584, 0.672, -0.672,\n",
    "        0.403, -0.403, -0.935, 0.974, -0.145, -0.647, 0.647, -0.234, -0.789, 0.878, -0.072, -0.269, 0.915, -0.789]\n",
    "assert list(preprocessed_train_X[0].round(3)) == row0\n",
    "preprocess_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "1b07tI86lVG_"
   },
   "source": [
    "## Tiền xử lý (tập validation) (1.5đ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "1Jk5vD1MlVG_"
   },
   "source": [
    "Một khi đã có `preprocess_pipeline` với các giá trị thống kê đã được tính từ tập huấn luyện, ta có thể dễ dàng dùng phương thức `transform` để tiền xử lý cho các véc-tơ input mới trong tập validation và tập kiểm tra. Dưới đây, bạn sẽ làm như vậy để tiền xử lý cho `val_X_df` và lưu kết quả vào `preprocessed_val_X`(chỉ cần duy nhất 1 dòng code thôi nhé)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "id": "3VVrWVhPlVG_",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "986f547abfe534258eb2c41f692c1084",
     "grade": false,
     "grade_id": "cell-5b00ff693785976e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "editable": false,
    "id": "un38UlKolVG_",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11d78d3e447c4f152ba6106fa18ad60f",
     "grade": true,
     "grade_id": "cell-b9c978682fecdf3c",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "assert preprocessed_val_X.shape == (49, 29)\n",
    "row0 = [-1.534, -0.797, -0.953, -0.72, 0.832, -0.503, -0.386, -0.269, -0.102, -0.29, -0.974, -0.421, 1.584, 0.672, -0.672,\n",
    "        0.403, -0.403, -0.935, 0.974, -0.145, 1.545, -1.545, -0.234, 1.268, -1.139, -0.072, -0.269, 0.915, -0.789]\n",
    "assert list(preprocessed_val_X[0].round(3)) == row0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "w0TV4YkvlVHA"
   },
   "source": [
    "Giải thích tại sao không nên làm 2 cách sau:\n",
    "- Tiền xử lý tập validation bằng các giá trị thống kê (mean, mode, ...) được tính từ tập validation\n",
    "- Hoặc tiền xử lý tất cả dữ liệu rồi mới tách tập validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "id": "rda_-rndlVHA",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a1567a9361126ee5dd2d6371498efda",
     "grade": true,
     "grade_id": "cell-c9f9e4ac63684628",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "esCTOTmclVHA"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "a6BCMtZElVHA"
   },
   "source": [
    "## Tiền xử lý + mô hình hóa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfvgdyEilVHB"
   },
   "source": [
    "### Tìm mô hình tốt nhất (4đ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "ni8OJ8h0lVHB"
   },
   "source": [
    "Ta sẽ sử dụng mô hình MLP để phân lớp. Bạn sẽ tạo ra một pipeline từ đầu đến cuối bao gồm: các bước tiền xử lý ở trên + MLP (với các siêu tham số `hidden_layer_sizes=(50), activation='relu', solver='lbfgs', random_state=0, max_iter=10000`). Bạn đặt tên cho pipeline này là `full_pipeline`. Việc tạo ra một pipeline từ đầu đến cuối như này có các lợi ích sau:\n",
    "- Giúp đơn giản hóa: \n",
    "    - Để huấn luyện từ đầu tới cuối, chỉ cần gọi phương thức `fit` của pipeline này trên tập huấn luyện dạng thô. Lúc này, các \"transformer\" ở các bước tiền xử lý sẽ gọi `fit_transform`, còn \"classifier\" ở cuối sẽ gọi `fit`.\n",
    "    - Với các véc-tơ input ở dạng thô, để dự đoán thì chỉ cần gọi phương thức `predict` của pipeline. Lúc này, các \"transformer\" ở các bước tiền xử lý sẽ gọi `transform`, còn \"classifier\" ở cuối sẽ gọi `predict`.\n",
    "- Giúp tránh tiền xử lý tập validation/kiểm-tra sai cách (như đã nói ở mục \"Tiền xử lý (tập validation)\" ở trên). Để làm sai cũng khó à nha ;-).\n",
    "- Giúp dễ dàng thử nghiệm đồng thời các giá trị của các siêu tham số ở các bước trong pipeline (sẽ làm ở ngay dưới).\n",
    "\n",
    "Sau khi đã có được pipeline từ đầu đến cuối này, bạn sẽ thử nghiệm:\n",
    "- Siêu tham số `alpha` (hệ số L2 regularization) của `MLPClassifier` với 5 giá trị khác nhau: từ 0 đến 100.\n",
    "- Siêu tham số `num_top_cp_values` của `ColAdderDropper` (ở bước tiền xử lý) với 5 giá trị khác nhau: 1, 3, 5, 7, 9.\n",
    "\n",
    "Để gán lại giá trị `alpha` và `num_top_cp_values` cho `full_pipeline`, bạn sẽ dùng phương thức `set_params`: \n",
    "\n",
    "`full_pipeline.set_params(mlpclassifier__alpha=...)`\n",
    "\n",
    "Nếu bạn tạo pipeline bằng `make_pipeline` thì tên của các bước sẽ được tự động lấy là tên của các class và được viết thường như 2 tên ở trên. Còn nếu bạn dùng `Pipeline` và tự đặt tên cho các bước thì bạn dùng tên của bạn trong phương thức `set_params`.  \n",
    "\n",
    "Như vậy, với mỗi mô hình bạn sẽ: huấn luyện trên tập huấn luyện, tính độ đo ở đây là độ chính xác (tỉ lệ dự đoán đúng) trên tập huấn luyện và tập validation rồi `append` độ đo vào 2 list tương ứng là `train_accs` và `val_accs` (để dễ nhìn, bạn tính độ chính xác theo đơn vị %, nghĩa là có giá trị từ 0-100 chứ không phải từ 0-1). Bạn lưu lại độ chính xác cao nhất trên tập validation và giá trị `alpha` và `num_top_cp_values` tương ứng lần lượt vào biến `best_val_acc`, `best_alpha`, `best_num_top_cp_values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "deletable": false,
    "id": "8axdeNeslVHB",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0662cf28420d8aab58040eaa80f76ed2",
     "grade": false,
     "grade_id": "cell-fdd12a79fb590313",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "3fa77a2f-0f1b-4b46-9522-005386b816d7",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tạo full_pipeline\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Thử nghiệm với các giá trị khác nhau của các siêu tham số (toàn bộ quá trình có thể mất từ 2-3 phút)\n",
    "# và chọn ra các giá trị tốt nhất\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "alphas = [0,0.01,0.1, 1, 10, 100]\n",
    "num_top_cp_values_s = [1, 3, 5, 7,9]\n",
    "best_val_acc = 0\n",
    "best_alpha = None\n",
    "best_num_top_cp_values = None\n",
    "for alpha in alphas:\n",
    "    for num_top_cp_values in num_top_cp_values_s:\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        \n",
    "'Finish!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "BAzogpDulVHC",
    "outputId": "dca91a52-7f70-4558-fcc4-c7c15ee053d8"
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "full_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "XoKMAgEulVHC",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f33688c1c8f4b1a71567209f5872b5e7",
     "grade": true,
     "grade_id": "cell-0b98eab69b5f1ff7",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert round(best_val_acc, 2) == 85.71\n",
    "assert best_alpha == 1\n",
    "assert best_num_top_cp_values == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "IFTBKkW5lVHC",
    "outputId": "035d35d6-db3e-417f-c464-92919cb2b727"
   },
   "outputs": [],
   "source": [
    "# Trực quan hóa kết quả\n",
    "train_accs_df = pd.DataFrame(data=np.array(train_accs).reshape(len(alphas), -1),\n",
    "                             index=alphas, columns=num_top_cp_values_s)\n",
    "val_accs_df = pd.DataFrame(\n",
    "    data=np.array(val_accs).reshape(len(alphas), -1), \n",
    "    index=alphas, columns=num_top_cp_values_s)\n",
    "min_err = min(min(train_accs), min(val_accs))\n",
    "max_err = max(max(train_accs), max(val_accs))\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(train_accs_df, vmin=min_err, vmax=max_err, square=True, \n",
    "            annot=True, cbar=False, fmt='.2f', cmap='Reds')\n",
    "plt.title('train accuracies'); plt.xlabel('num_top_cp_values'); plt.ylabel('alpha')\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(val_accs_df, vmin=min_err, vmax=max_err, square=True, \n",
    "            annot=True, cbar=False, fmt='.2f', cmap='Reds')\n",
    "plt.title('validation accuracies'); plt.xlabel('num_top_cp_values'); plt.ylabel('alpha');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "wKoaXVyTlVHC"
   },
   "source": [
    "Nhận xét về ảnh hưởng của siêu tham số `alpha` (có sao thì bạn nói vậy, chỗ nào không biết thì nói là không biết): \n",
    "- Bạn kỳ vọng khi `alpha` thay đổi thì độ chính xác trên tập huấn luyện và tập validation sẽ thay đổi như thế nào? Tại sao bạn lại kỳ vọng như vậy?\n",
    "- Kết quả ở trên có giống như kỳ vọng của bạn không? Nếu không thì bạn nghĩ xem tại sao lại như vậy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "rrIpJ6D6lVHC",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e0471605e1a0872e36754fa0f485aa1",
     "grade": true,
     "grade_id": "cell-4debcfe69b8e605b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "7bYIi4s8lVHD"
   },
   "source": [
    "Nhận xét về ảnh hưởng của siêu tham số `num_top_cp_values` (có sao thì bạn nói vậy, chỗ nào không biết thì nói là không biết): \n",
    "- Bạn kỳ vọng khi `num_top_cp_values` thay đổi thì độ chính xác trên tập huấn luyện và tập validation sẽ thay đổi như thế nào? Tại sao bạn lại kỳ vọng như vậy?\n",
    "- Kết quả ở trên có giống như kỳ vọng của bạn không? Nếu không thì bạn nghĩ xem tại sao lại như vậy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "TSylFa2NlVHD",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "49982bae0349935c9ca94046bf830735",
     "grade": true,
     "grade_id": "cell-94737f293bd3c2a8",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9-G4HQRlVHD"
   },
   "source": [
    "Cuối cùng, bạn sẽ huấn luyện lại `full_pipeline` trên `X_df` và `y_sr` (tập huấn luyện + tập validation) với `best_alpha` và `best_num_top_titles` tìm được ở trên để ra được mô hình cụ thể cuối cùng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "deletable": false,
    "id": "_H4FSj9FlVHD",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e771c0641435719860146ab39be71ef8",
     "grade": true,
     "grade_id": "cell-34157b0f98b9d3f5",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "94073c48-5ba8-4a02-ff84-99f2dfbfb892"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "s7un-crLlVHD"
   },
   "source": [
    "### Đánh giá mô hình tìm được (1đ)\n",
    "Bạn sẽ dùng mô hình cụ thể cuối cùng ở trên để dự đoán với các input trong tập test (file \"lab03_test.csv\"). Để mình có thể chấm điểm (so sánh với groundtruth đã bị ẩn) thì bạn phải tạo ra file csv có 1 cột `target` duy nhất là giá trị dự đoán của bạn (1 - có bệnh, và 0 - không). Bạn đặt tên file của bạn là `my_preds.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5jk7q3AaygtG"
   },
   "outputs": [],
   "source": [
    "test_X_df = pd.read_csv(\"lab03_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6lbh5jeywFl"
   },
   "outputs": [],
   "source": [
    "test_X_df.to_csv(\"lab03_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "deletable": false,
    "id": "YXC5LEqNlVHE",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "226b0f0ebb7e79c2866d02164cec9e2d",
     "grade": false,
     "grade_id": "cell-e184d7a3003ba334",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1d6trk_elVHE",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1ff8fb8e8c561377393942df69da26c",
     "grade": true,
     "grade_id": "cell-dbdc218117501513",
     "locked": true,
     "points": 0.75,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "my_preds_df = pd.read_csv('my_preds.csv')\n",
    "assert round(my_preds_df['target'].mean(), 3) == 0.574\n",
    "assert np.all(my_preds_df.iloc[:5].values.reshape(-1) == \\\n",
    "                                     np.array([0, 0, 1, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oy9yh-uEiiXr"
   },
   "source": [
    "### Thí nghiệm với các mô hình phân lớp khác (Bonus, tối đa 2đ).\n",
    "\n",
    "Trong phần này, các bạn có thể thử các mô hình phân lớp khác với MLP ở phần trên để tối ưu độ chính xác trên tập validation (hoặc test) nhất có thể. \n",
    "\n",
    "Các bạn có thể thử trên subset của các features để tìm ra bộ features tối ưu nhất. Hoặc Các bạn cũng có thể thử **tinh chỉnh** các siêu tham số của mô hình MLP ở trên để tìm ra bộ tham số tối ưu hơn (chẳng hạn như `hidden_layer`, `activation`, `solver`, `learning_rate`). Bạn nào có kết quả trên tập test (của mình) càng cao thì càng được nhiều điểm nhé 💪💪💪\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H4f1J1ODimKg"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab03 - Implemented",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "153px",
    "width": "252px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "176px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
